{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-08T17:45:30.670948Z",
     "start_time": "2024-04-08T17:45:30.664964Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# reads in the json file, only to the max entries and returns them as json_array, if max entries is set to 0 then it reads the full thing\n",
    "def read_partial_json_file(filename, max_entries=0, encoding='utf-8'):\n",
    "    json_array = []\n",
    "    with open(filename, 'r', encoding=encoding) as file:\n",
    "        if max_entries == 0:\n",
    "            for line in file:\n",
    "                json_array.append(json.loads(line))\n",
    "        else:\n",
    "            for _ in range(max_entries):\n",
    "                line = file.readline()\n",
    "                if not line:\n",
    "                    break\n",
    "                json_array.append(json.loads(line))\n",
    "    return json_array\n",
    "\n",
    "def add_missing_keys(json_array):\n",
    "    for obj in json_array:\n",
    "        for key in ['stars', 'useful', 'funny', 'cool', 'text']:\n",
    "            if key not in obj:\n",
    "                obj[key] = 0\n",
    "                if key == 'stars':\n",
    "                    obj[key] = 3\n",
    "                print(\"Key {} not found in json\".format(key))\n",
    "    return json_array\n",
    "\n",
    "# removes specified keys from json array\n",
    "def remove_keys(json_array, keys_to_remove):\n",
    "    for obj in json_array:\n",
    "        for key in keys_to_remove:\n",
    "            obj.pop(key, None)\n",
    "    return json_array\n",
    "\n",
    "def ConvertJSONFileToDataFrame(filename, max_entries=1000, encoding='utf-8'):\n",
    "    #load in the json array\n",
    "    json_array = read_partial_json_file(filename, max_entries, encoding)\n",
    "    #add in the missing keys, will set to 0 for now but a heuristic for this will have to be made.\n",
    "    json_array = add_missing_keys(json_array)\n",
    "    df = pd.DataFrame(json_array)\n",
    "    ColumnsToRemove = ['business_id', 'user_id', 'date', 'review_id']\n",
    "    df = df.drop(columns=ColumnsToRemove)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T17:45:30.684380Z",
     "start_time": "2024-04-08T17:45:30.673938Z"
    }
   },
   "id": "32a14b2fda56c4c",
   "execution_count": 210
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 9701)\n",
      "(160, 9701)\n",
      "torch.Size([640, 9701])\n",
      "torch.Size([640])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filename = 'yelp_academic_dataset_review.json'\n",
    "df = ConvertJSONFileToDataFrame(filename)\n",
    "#df.head(10)\n",
    "\n",
    "# X = df[['useful', 'funny', 'cool', 'text']]\n",
    "# y = df[['stars']]\n",
    "\n",
    "X = df['text']\n",
    "y = df['stars']\n",
    "\n",
    "X_im, X_valid, y_im, y_valid = train_test_split(X, y, test_size=0.2, random_state=117)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_im, y_im, test_size=0.2, random_state=312)\n",
    "\n",
    "vectorizer = CountVectorizer(lowercase=False)\n",
    "vectorizer.fit(df['text'])\n",
    "\n",
    "X_train_vec = vectorizer.transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "print(X_train_vec.shape)\n",
    "print(X_test_vec.shape)\n",
    "\n",
    "X_train.head(10)\n",
    "\n",
    "# json_array = read_partial_json_file(filename, 1000, 'utf-8')\n",
    "# json_array = add_missing_keys(json_array)\n",
    "# json_array = remove_keys(json_array, ['business_id', 'user_id', 'date', 'review_id'])\n",
    "# \n",
    "# print(json_array[0])\n",
    "\n",
    "X_train_tensor = torch.from_numpy(X_train_vec.todense()).float()\n",
    "X_test_tensor = torch.from_numpy(X_test_vec.todense()).float()\n",
    "Y_train_tensor = torch.from_numpy(np.array(y_train))\n",
    "Y_test_tensor = torch.from_numpy(np.array(y_test))\n",
    "\n",
    "print(X_train_tensor.shape)\n",
    "print(Y_train_tensor.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T17:45:30.923881Z",
     "start_time": "2024-04-08T17:45:30.692454Z"
    }
   },
   "id": "5ffe735463d493ca",
   "execution_count": 211
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#I don't have a GPU on my laptop so this is untestable\n",
    "if torch.cuda.is_available():\n",
    "    torchDevice = torch.device('cuda')\n",
    "else:\n",
    "    torchDevice = torch.device('cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T17:45:30.929894Z",
     "start_time": "2024-04-08T17:45:30.925873Z"
    }
   },
   "id": "4df2077b4035cc5e",
   "execution_count": 212
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, vocabSize, embed_size, layer1size, layer2size, layer3size, dropout, maxWordCt):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(maxWordCt * vocabSize, embed_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.feed = nn.Linear(embed_size, layer1size)\n",
    "        self.full1 = nn.Linear(layer1size, layer2size)\n",
    "        self.full2 = nn.Linear(layer2size, layer3size)\n",
    "        self.full3 = nn.Linear(layer3size, 5) #the output is just projected star count\n",
    "        \n",
    "        #First fully connected layer\n",
    "        self.fc1 = torch.nn.Linear(vocabSize,layer1size)\n",
    "        #Second fully connected layer\n",
    "        self.fc2 = torch.nn.Linear(layer1size,5)\n",
    "        #Final output of sigmoid function      \n",
    "        self.output = torch.nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, text):\n",
    "        #return self.linear(text)\n",
    "        fc1 = self.fc1(text)\n",
    "        fc2 = self.fc2(fc1)\n",
    "        output = self.output(fc2)\n",
    "        return output[:, -1]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        x = embedded.view(embedded.shape[0], -1)\n",
    "        x = self.relu(self.feed(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.full1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.full2(x))\n",
    "        x = self.dropout(x)\n",
    "        result = self.full3(x)\n",
    "        return result\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T17:45:30.939859Z",
     "start_time": "2024-04-08T17:45:30.931879Z"
    }
   },
   "id": "d8f937879dd66469",
   "execution_count": 213
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):    \n",
    "    def __init__(self,vocab_size,hidden_units,num_classes): \n",
    "      super().__init__()\n",
    "      #First fully connected layer\n",
    "      self.fc1 = torch.nn.Linear(vocab_size,hidden_units)\n",
    "      #Second fully connected layer\n",
    "      self.fc2 = torch.nn.Linear(hidden_units,num_classes)\n",
    "      #Final output of sigmoid function      \n",
    "      self.output = torch.nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "      fc1 = self.fc1(x)\n",
    "      fc2 = self.fc2(fc1)\n",
    "      output = self.output(fc2)\n",
    "      return output[:, -1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T17:45:30.950830Z",
     "start_time": "2024-04-08T17:45:30.941898Z"
    }
   },
   "id": "183c77f8c21ce3d1",
   "execution_count": 214
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (640x9701 and 300x128)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[215], line 5\u001B[0m\n\u001B[0;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m NeuralNet(X_train_vec\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], \u001B[38;5;241m300\u001B[39m, \u001B[38;5;241m128\u001B[39m, \u001B[38;5;241m64\u001B[39m, \u001B[38;5;241m32\u001B[39m, dropout\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m, maxWordCt\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m#print(X_train_tensor)\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_tensor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(pred)\n",
      "File \u001B[1;32mC:\\Repos\\AIProject2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Repos\\AIProject2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[213], line 22\u001B[0m, in \u001B[0;36mNeuralNet.forward\u001B[1;34m(self, text)\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, text):\n\u001B[0;32m     21\u001B[0m     x \u001B[38;5;241m=\u001B[39m text\n\u001B[1;32m---> 22\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     23\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout(x)\n\u001B[0;32m     24\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfull1(x))\n",
      "File \u001B[1;32mC:\\Repos\\AIProject2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Repos\\AIProject2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Repos\\AIProject2\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 116\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (640x9701 and 300x128)"
     ]
    }
   ],
   "source": [
    "model = NeuralNet(X_train_vec.shape[1], 300, 128, 64, 32, dropout=0.5, maxWordCt=100)\n",
    "\n",
    "#print(X_train_tensor)\n",
    "\n",
    "pred = model(X_train_tensor)\n",
    "print(pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T17:45:36.885884Z",
     "start_time": "2024-04-08T17:45:30.952823Z"
    }
   },
   "id": "872a57e8cd11bde",
   "execution_count": 215
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trainData = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "print(trainData[0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e05cf63de732ad6d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trainLoader = DataLoader(trainData, batch_size=16, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-08T17:45:36.901887Z"
    }
   },
   "id": "eb874800f4b9dfbe",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Initialize optimizer\n",
    "optimizer =torch.optim.SGD(model.parameters(), lr=0.001)#Initialize loss function\n",
    "loss_fun = nn.BCELoss() \n",
    "\n",
    "model.train()\n",
    "\n",
    "for i in range(5):   \n",
    "    for x_batch,y_batch in trainLoader:       \n",
    "        model.train()\n",
    "        y_pred = model(x_batch)\n",
    "        loss = loss_fun(y_pred,y_batch.float())\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "print('After {} epoch training loss is {}'.format(i,loss.item()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-08T17:45:36.903878Z"
    }
   },
   "id": "ff57f6e0c2a86ad5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m2 = Network(X_train_vec.shape[1], 3, 5)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)  #Initialize loss function\n",
    "loss_fun = nn.BCELoss()\n",
    "\n",
    "model.train()\n",
    "\n",
    "for i in range(5):\n",
    "    for x_batch, y_batch in trainLoader:\n",
    "        model.train()\n",
    "        y_pred = model(x_batch)\n",
    "        loss = loss_fun(y_pred, y_batch.float())\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "print('After {} epoch training loss is {}'.format(i, loss.item()))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-08T17:45:36.905884Z"
    }
   },
   "id": "3000dc1eaf9194d2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-08T17:45:36.906871Z"
    }
   },
   "id": "f830db7df5e30801",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
